\documentclass[12pt]{article}

\usepackage{tgtermes}
\usepackage{epsf}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{dcolumn}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{mwe}
\usepackage{url}
%\usepackage{harvard}
\usepackage{fancyheadings}
\usepackage{longtable}
\usepackage{authblk}
\usepackage{setspace}
%\usepackage[nomarkers]{endfloat}
\usepackage{float}
\usepackage{bbm}
%\usepackage{titling}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{import}
\usepackage[backend=biber,style=authoryear,
sorting=ynt,citestyle=authoryear]{biblatex}
\addbibresource{papercitations.bib}
%\usepackage[nomarkers,nofiglist,notablist]{endfloat}

\onehalfspacing
\textwidth 6.5in \oddsidemargin 0in \evensidemargin -0.6in
\textheight 8.5in \topmargin -0.2in

\newcolumntype{L}[1]{>{\raggedright\let\newline\\
		\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\
		\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\
		\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{P}[1]{>{\raggedright\tabularxbackslash}p{#1}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}

\captionsetup{justification=center,singlelinecheck=false}


\newcommand{\xsub}[1]{%
	\mbox{\scriptsize\begin{tabular}{@{}c@{}}#1\end{tabular}}%
}

%\renewcommand{\thetable}{\Roman{table}}

\begin{document}
	
	
	
	
	\linespread{1.2}\title{\vspace{-0.5in} Does Hospital Leadership Matter?\\ \large Evidence from Pay-for-Performance Incentives} 
	
	\date{\today}
	
	\author{\vspace{10mm}Hanna Glenn\footnote{Department of Economics, Emory University, 1602 Fishburne Drive, Atlanta, GA 30322, hanna.glenn@emory.edu.} }
	
	\maketitle
	%\setlength{\droptitle}{-10pt}
	
	\vspace{-0.2in}
	
	\singlespacing\maketitle

    \begin{center}
    \large
    \textbf{This is a preliminary draft. Please do not cite or circulate.}
	\end{center}

 \vspace{3mm}
	
    \begin{abstract}
		{\small
        In many industries, including hospitals, nonprofits make up the majority of firms in the market. Understanding the objectives and behaviors of these firms is important when creating incentives. However, nonprofit firms have diverse goals and missions that make understanding their objectives difficult. For hospitals in particular, there is mixed evidence on whether nonprofit hospitals differ meaningfully from for-profit hospitals. In this paper, I investigate whether leadership team composition of nonprofit hospitals affects how similarly they behaves to for-profits. I use a novel data set on nonprofit hospital executives in the US from 2009-2015 to investigate whether the existence of clinical training on a hospital executive team affects hospital behavior. In particular, I leverage several pay-for-performance initiatives in the US in 2012, and estimate the difference in response between for-profits, nonprofits, and nonprofits with clinically trained executives. I find that while readmissions decreased on average for all types of hospitals, the response was larger for for-profits and nonprofits without clinically trained executives. This is consistent with theoretical predictions under the assumption that nonprofits with clinically trained executives put higher weight on societal outcomes than those without clinically trained executives.
		} 
	\end{abstract}
	
	
	
	
	\vspace{0.8in}
	
	\noindent Keywords: 
	
	\noindent JEL Codes: 
	
	\onehalfspacing
	
	\newpage

  The objectives and behaviors of firms that are not classic for-profits are not easily determined, and an extensive literature has sought to understand these types of firms. Nonprofits are thought to gain utility not solely from monetary profit, but also through accomplishing societal benefit. Researchers have speculated a variety of objective functions that could motivate nonprofits such as maximizing prestige, income, or a quality/quantity trade-off (\cite{steinberg1986revealed}). Empirical contributions to this literature center around investigating behaviors that differ between for-profit, private nonprofit, and government firms (\cite{sloan2000not}). In this paper, I investigate whether differences in observed behavior between for-profit and nonprofit hospitals vary differentially by nonprofit leadership team composition. 
  
  Hospitals have been a common focus when seeking to understand nonprofit firms. This is because, first, there are different hospital ownership types within the industry, giving researchers the ability to compare the behaviors of nonprofits with that of for-profits. Second, private nonprofit hospitals make up 50\% of all hospitals in the US, and staff, on average, 207 beds. For comparison, for-profits make up around 36\% of hospitals and staff 107 beds (\cite{ASPE_2023}). Thus, nonprofit behavior in the hospital industry is relevant, and directly affects consumers of health care. However, it remains unclear what objective function drives nonprofit hospital behavior, and whether nonprofit hospitals are meaningfully different from for-profits (\cite{sloan2000not}; \cite{erus2002inferring}; \cite{deneffe2002not}; \cite{horwitz2009hospital}). 
  
  While the characterization of being for-profit or nonprofit is certainly important, there could be other characteristics that drive objectives and behavior that are not perfectly correlated with ownership status. Particularly, firm leadership varies widely across firms and potentially drives differences in objectives even within nonprofits. In large, publicly traded firms, executive characteristics are shown to be correlated with firm performance, indicating that there is more to firm behavior than for-profit or nonprofit status (\cite{bertrand2003managing}; \cite{matsa2013female}; \cite{ahern2012changing}). If hospital objectives differ in the weights placed on profit vs. societal benefit, then ownership status certainly plays a role in these weights, but characteristics of those managing the hospital could also play an important role. I contribute to our understanding of hospital and nonprofit behaviors by investigating whether occupational background, whether executives have clinical training, affects response to pay-for-performance incentives.

  Using publicly available tax forms, I construct a novel data set of nonprofit hospital executives from 2009-2015. I link hospitals in this data to characteristics in the American Hospital Association survey and Hospital Compare data. I leverage various pay-for-performance initiatives enacted in 2012 to investigate differential hospital responses between for-profits, nonprofits without clinically trained executives, and nonprofits with clinically trained executives. While executive teams change over time, I find no evidence that they change in response to the programs. This allows me to investigate the role of particular executives in two ways. First, I analyze the differential response to incentives of nonprofits who ever hire a clinically trained executive, as this might be a signal of underlying preferences. Second, I analyze the differential response of nonprofits who have a clinically trained executive in 2012 compared to those who have a clinically trained executive at other times, but not in 2012. These two analyses aim to disentangle the effect of the actual leadership team from the underlying preferences of the hospital. 
  
  I estimate how the interaction between hospital type and post program enactment affects readmission and mortality rates among different groups. Under the assumption that hospitals would have continued to behave similarly in the absence of the programs, and that leadership teams do not change endogenously with the programs, I identify the differential response to pay-for-performance incentives by different hospital types. Among the hospitals in the data, hospitals with clinically trained executives are the minority, and differ on average from other hospitals along various dimensions. Thus, my preferred specification is synthetic difference-in-differences, to analyze a group of comparison hospitals with similar characteristics to treatment hospitals.\footnote{I also present results for the full sample, and with a pre-analysis matching procedure and find qualitatively similar results.} 
  
   While all hospital types decrease readmission rates after the programs are enacted, for-profits and nonprofits without clinically trained executives decrease readmissions more than nonprofits without clinically trained executives. That is, nonprofits without clinically trained executives respond to incentives more similarly to for-profits than other nonprofits. To investigate the mechanisms by which hospitals decrease readmissions, I also conduct the analyses with uncompensated care and case mix index as outcomes. (results of this analysis here)

    This paper contributes to three strands of literature. First, it adds to our understanding of what underlies nonprofit hospital behavior. This literature is extensive, and a review of it is beyond the scope of this paper. To summarize, there are various aspects of nonprofit behavior and objectives for which the evidence of how much it differs from for-profits remains mixed: costs, uncompensated care, technology adoption, and quality (\cite{sloan2000not}; \cite{eggleston2008hospital}; \cite{moscelli2018effect}; \cite{moscone2020public}). What underlies this is the need to understand the ways in which nonprofits make choices differently than for-profits. To this point, researchers have found that nonprofits do not act as purely profit maximizers, but maximize some combination of profit and output (\cite{deneffe2002not}, \cite{chang2011nonprofit}). A paper with an approach similar to mine which investigates hospital behavior is \citeauthor{chang2011nonprofit} (\citeyear{chang2011nonprofit}), which looks at the effect of a cost shock on likelihood of shutting down and mix of profitable services. They find that nonprofits and for-profits are equally as likely to shut down after the shock, but only nonprofits adjust their mix of profitable services. Similarly, I investigate a change in incentives to hospitals, but I look at the differential impacts of leadership teams within nonprofits. This paper adds to our understanding of inputs into nonprofit hospital objective functions. 

    Second, many researchers have documented a correlation between executive backgrounds, specifically for CEOs, and firm performance, starting with \citeauthor{bertrand2003managing} (\citeyear{bertrand2003managing}), who show that manager fixed effects are an important driver of many firm behaviors and decisions. Female board members are associated with better oversight and more women executives (\cite{matsa2011chipping}; \cite{adams2009women}), but are negatively correlated with firm value (\cite{ahern2012changing}). Having more female executives is correlated with choices of female employee wages and corporate strategies (\cite{flabbi2019female}; \cite{matsa2013female}); young male CEOs tend to be more aggressive in mergers and acquisitions, while those with military experience are less aggressive (\cite{levi2010deal}; \cite{benmelech2015military}); CEOs with general ability tend to receive higher pay and perform better (\cite{kaplan2012ceo}; \cite{custodio2013generalists}, \cite{adams2018director}; \cite{frydman2019rising}). Further, Chief Diversity Officers are not found to have any effect on hiring more diversely in universities (\cite{bradley2022impact}). Due to data limitations, many of these studies focus on large, publicly traded firms in the US. However, one study uses data from England to study whether CEOs affect hospital production, and find no association (\cite{janke2019impact}). \textcolor{red}{(add paper about Chile hospital executives)}. I contribute to this literature first by investigating a context which is not largely studied but is policy relevant, nonprofit US hospitals, and considering a unique executive characteristic pertinent to that context. 

    Finally, I contribute to our understanding of how providers respond to pay-for-performance incentives in health care. The most in depth study of how hospitals respond to HRRP is \citeauthor{gupta2021impacts} (\citeyear{gupta2021impacts}). The author finds that hospitals decreased readmissions by 5\% and mortality rates by 2\% on average as a result of the program, confirming prior studies (\cite{mellor2017does}; \cite{ziedan2018essays}; \cite{ody2019decreases}; \cite{gupta2021impacts}). Importantly, around 40\% of the decrease in readmissions is due to selective patient practices. This raises important questions about how to incentivize improvement in quality of care without also incentivizing gamesmanship. This paper addresses a necessary first step in considering whether leadership compositions could affect likelihood of gaming. \textcolor{red}{(add papers about other program too)}

    

    \section{Institutional Setting}

    \subsection{Hospital Readmissions Reduction Program}\label{sec:hrrp}

    The Hospital Readmissions Reduction Program (HRRP) was passed as a part of the Affordable Care Act in 2010 as a pay-for-performance incentive for hospitals to increase quality. In October 2011, the Center for Medicare and Medicaid Services (CMS) released a set of rules that mandated penalties for hospitals with above average readmission rates. A readmission is when a patient returns to the hospital within 30 days of being discharged from a previous stay; avoidable readmissions are a bad outcome for patients and increase health care spending. The goal of HRRP is to lower readmissions through better care coordination, less initial stay complications, and better post-care instructions. Beginning in October 2012, hospitals with higher readmission rates than the national average in pneumonia, heart failure, or AMI (after adjusting for demographic characteristics) receive a lower reimbursement rate for Medicare patients. In 2015, CMS also included chronic obstructive pulmonary disease, coronary artery bypass graft surgery, and elective primary total hip arthroplasty and/or total knee arthroplasty as conditions which go into the penalty calculation. \textcolor{red}{(add citations??)}
    
    Penalized hospitals pay penalties in the form of a fixed rate for every Medicare patient regardless of the condition. Further, CMS does not distinguish a necessary readmission from an avoidable readmission; any repeat hospital visit is included in the penalty calculation. Excess readmission rates are calculated using a rolling look-back period of 3 years to determine whether the hospital is penalized. Therefore, hospitals had incentive to react immediately once details of the program were announced in October of 2011. These penalties are not insignificant; penalized hospitals paid, on average, 4-5\% of revenue. 

    \textcolor{red}{(is the program still going?)}

    \subsection{Hospital Value-Based Purchasing Program}

    \subsection{Nonprofit Hospital Leadership}

    Nonprofits are governed by a board of directors, whose role is to set high level goals and strategies, and provide general oversight. The board is not in charge of day-to-day operations, but the general direction of the firm. They select members of the executive team to carry out day-to-day operations. While hospital executives typically do specialize by getting degree(s) in healthcare management or an MBA specific to healthcare, they do not often have clinical training. While some doctors earn additional degrees before stepping into an executive role, this is not a necessary condition to becoming a physician executive. An executive team usually consists of at least a CEO and CFO, but every nonprofit is different in exactly how they structure their executive team. Some nonprofits hire Chief Medical Officers, Chief Quality Officers, executive directors, vice presidents of various departments, etc. I consider all of these employees as part of the day-to-day management of the hospital and include them as a part of the executive team. 

    All tax-exempt organizations in the US are required to file a Form 990 with Internal Revenue Services (IRS) each year. There are different types of forms, but any organization grossing over \$200,000 must file the most extensive Form 990. Sections of this form include a statement of revenue, statement of functional expenses, a balance sheet, and, as used in this project, a list of all key employees, executives, and board members. In this section, each firm is required to report the name and title, average hours per week, position, and compensation of their board members and executive leaders. Since these firms are tax exempt, their information in these forms is made publicly available.  

  
	
	\section{Data}\label{sec:data}

    \subsection{Names of Hospital Leaders}

    To characterize hospitals as having clinically trained executives or not, I construct a novel data set of nonprofit hospitals in the US that contains names and select characteristics of executives tied to the hospital from 2009-2015. I gather this data from each hospital's publicly available Tax Form 990, which every sufficiently large nonprofit files each year in the US. To my knowledge, this is the first large scale gathering of leadership names from these forms. 

    The historical tax forms for all nonprofits are housed by ProPublica.\footnote{https://projects.propublica.org/nonprofits/} I use the NonProfit Explorer API to extract the Employee Identification Numbers (EIN) of all nonprofits classified as a hospital according to their National Taxonomy of Exempt Entities (NTEE) code. After filtering out associations and specialty hospitals, there are around 3,000 firms left. Importantly, I need to be able to link hospitals in the tax forms to other hospital characteristics from publicly availble sources. No official crosswalk between EINs and AHA IDs or Medicare numbers exists, so I must rely on matching by location and name of hospital in both data sets. After limiting to only general, nonprofit hospitals that I can link to the AHA survey, I confidently match approximately 1200 EINs to an AHA identification number based on exact name matches within the same state. 
    
    For each of the 1200 EINs, I then extract web URLs to Form 990 PDFs in each year. I download these locally and use optical character recognition (OCR) text extraction methods to scrape the relevant section of the pdf, which is titled ``Officers, Directors, Trustees, Key Employees, and Highest Compensated Employees". Finally, I use string cleaning methods to identify names and positions for each EIN, year. I also identify titles indicating a physician: MD, Dr., or DO. Using OCR extraction can be unreliable in some instances when the text is handwritten or the font is too small. Therefore, I manually find names, positions, and titles for observations that are missing after the initial extraction. This yields 850 EINs that are matched to AHA data, and are not missing text information. 

    Due to the lack of consistency in organization of executive teams, I focus mainly on the executive teams as a whole instead of specific positions. I drop anyone who is solely a board member, and focus on those who have executive in their title or are labeled as a president or vice president of a specific aspect of the hospital. I create various hospital-level characterizations based on their executive teams, such as the existence of a clinically trained executive, the number of clinically trained executives, the number of total executives, and whether the hospital has a Chief Medical Officer.


    \subsection{Other Hospital Characteristics and Outcomes}

    I include hospital information from the AHA survey on the number of beds in the hospital and the Medicare number, which I use to merge the Hospital Compare and Healthcare Cost Reporting Information System (HCRIS) data. Further, I use the AHA categorization of for-profit or nonprofit. Hospital Compare contains information on penalties from HRRP and readmission and mortality rates for the relevant HRRP conditions: heart failure, heart attack (AMI), and pneumonia. From HCRIS, I gather information on penalties from the HVBP program, operating expenses, and uncompensated care. I also link to the publicly available CMS file containing each hospital's case mix index.

    The Hospital Compare excess readmissions files contain information on the excess readmission measure used by CMS to determine whether a hospital should be penalized. Specifically, CMS calculates the average readmission rate of all hospitals, adjusts for demographic factors, and determines the amount of readmissions a hospital has in excess to of the average. This variable is condition specific, where a hospital is penalized if any of the three excess readmission ratios are greater than one\footnote{Additional conditions were added to the penalty calculations in 2015, but I do not consider these since my sample does not extend past 2015}. Further, Hospital Compare also publishes hospital level readmission and mortality rates for heart failure, AMI, and pneumonia. For my main outcomes of interest, I take an average across conditions, weighted by the total number of patients seen for that condition.

    \subsection{Summary Statistics}

    \import{Tables}{overall_sumstats.tex}

    \import{Tables}{sample_sumstats.tex}

    \import{Tables}{stable_sample_sumstats.tex}

    In Table \ref{sumstats}, I present summary statistics for hospital variables. There are 3,766 total hospitals in the sample, with 150 beds on average. Hospitals in the sample are less likely to be penalized for AMI than either heart failure or pneumonia under the HRRP program. On average, 20\% of patients with one of these conditions would be readmitted. While readmission rates for the specific conditions are similar, the highest likelihood of readmission is for heart failure patients. Alternatively, AMI is the most dangerous condition in terms of mortality rates. 

    %\import{Tables}{overall_sumstats.tex}

    I present a table of means for each hospital type (for-profit, all nonprofits, nonprofits with a clinically trained executive, and nonprofits without a clinically trained executive) in Table \ref{tab:sumstats_samples}. Eighty-five percent of hospital in the sample are classified as nonprofits. Importantly, the two sub-samples of nonprofits do not add up to the total number of nonprofits because of the limited ability to extract leadership text for all nonprofits. There are key differences in nonprofits with and without clinically trained executives: those with MDs are larger, more likely to be penalized, have higher uncompensated care, and more complex patients.  

    %\import{Tables}{sample_sumstats.tex}

    I plot readmission and mortality rates across time for different hospital types in Figure \ref{fig:weighted_read_mort_graph}. While this is purely descriptive evidence, the trends in outcomes point to more similar behavior between for-profits and nonprofits without clinically trained executives in comparison to nonprofits with a clinically trained executive.

    \begin{figure}[ht!]
    \centering
        \caption{Outcomes over time in all penalized hospitals}
        \includegraphics[width=\textwidth]{Objects/weighted_read_mort_graph.pdf}
        \label{fig:weighted_read_mort_graph}
    \end{figure}

    Finally, I present a table of correlations between having at least one clinically trained executive and other time invariant hospital characteristics. There may be a concern that this particular characteristic of executive teams is simply a proxy for another quality, such as being an academic medical center. Unsurprisingly, the most correlated characteristic with having a clinically trained executive is having a CMO on the executive team. However, even this correlation is only .4, meaning there is still variation in having clinically trained executives even when controlling for having a CMO. 

    \import{Tables}{hosp_correlations.tex}

    

    \section{Model and Empirical Strategy}\label{sec:model}

    \subsection{First Period}

    Not knowing the true form of hospital objective functions, we can consider them maximizing some weighted average of profit and societal (or patient) benefit. Abstracting away from quantity and price as functions of quality for the purpose of this paper, I present a two-stage model of firm behavior that captures the change of quality due to pay-for-performance incentives. In the first period, prior to program enactment, hospitals do not expect any penalties in the future, and choose quality according to:    
    
    $$\max_{\theta}\hspace{2mm}\alpha\left[R - c_{\theta}(\theta) \right] + (1-\alpha) u(\theta),$$

    \noindent where $R$ is net revenue, $c_{\theta}(.)$ is an increasing cost function specific to quality $\theta$, $u(.)$ is extra utility, which is increasing and concave is $\theta$, and $\alpha\in[0,1]$ is a hospital's type, indicating how much they care about profit vs. societal benefit. There is an implicit stay open condition throughout the model. Taking the first order condition yields 

    $$(1-\alpha)u'(\theta) = \alpha c_{\theta}'(\theta),$$

    \noindent marginal benefit of increasing quality equals marginal cost. Solving for $u'(\theta)$ and differentiating with respect to $\alpha$ yields

    $$\frac{du'(\theta)}{d\alpha} = c_{\theta)}'(\theta)\frac{1}{(1-\alpha)^2} > 0.$$

    Thus, by the Implicit Function Theorem, 

    $$\frac{d\theta}{d\alpha} = \frac{du'(\theta)/d\alpha}{du'(\theta)/d\theta} < 0.$$

    That is, the more weight the hospital places on profit, the lower quality of care they will provide.

    \subsection{Second Period}

    Hospitals determine period 1 quality $\theta_1$ according to $\theta(\alpha)$ described above. Then, in period two, hospitals are penalized according to $\theta_1$, and they choose a new quality, $\theta_2$, which will determine penalties in the future. The penalty $(k)$ comes in the form of a negative shock to revenue for hospitals with quality below a certain threshold. That is,

    $$R_2 = \begin{cases}
        R - k, \text{  if  } \theta_1<\overline{\theta}\\
        R, \text{  if  } \theta_1\geq \overline{\theta}.
    \end{cases}$$

    The penalty $k$ is large and exceeds the maximum cost of quality. The penalty threshold, $\overline{\theta}$, is exogenous. Since $k>max\{c_{\theta}(\theta)\}$, all hospitals will choose $\theta_2$ to not be penalized in the future. Thus,

    $$\theta_2 = \begin{cases}
        \overline{\theta}, \text{  if  } \theta_1<\overline{\theta}\\
        \theta_1, \text{  if  } \theta_1\geq \overline{\theta}.
    \end{cases}$$

    Taking the change in theta from period 1 to period 2, 

    $$\Delta\theta = \theta_2-\theta_1 = \begin{cases}
        \overline{\theta}-\theta_1, \text{  if  } \theta_1<\overline{\theta}\\
        0, \text{  if  } \theta_1\geq \overline{\theta}.
    \end{cases}$$

    Differentiating with respect to $\alpha$, we get 

    $$\frac{d\Delta\theta}{d\alpha} = \begin{cases}
        -\frac{d\theta_1}{d\alpha}, \text{  if  } \theta_1<\overline{\theta}\\
        0, \text{  if  } \theta_1\geq \overline{\theta}.
    \end{cases}$$

    I show in period one that $\frac{d\theta}{d\alpha}<0$. Therefore, $\frac{d\Delta\theta}{d\alpha}>=0$. That is, the response to the program incentives is weakly increasing in $\alpha$, and there is a threshold for which increasing $\alpha$ (a hospital with more weight on profit), increases the response to the penalty. 

    The theoretical prediction is that change in quality depends on how much weight the hospital places on profit vs. societal benefit. However, $\alpha$ for each hospital is unobserved. Thus, I empirically investigate whether the response to the program is correlated with hospital ownership or clinical training on the executive team in order to gain understanding about $\alpha$. 

    \subsection{Estimation}

    First, I test empirically whether different sub-samples of nonprofits respond to program incentives differently from for-profits. While nonprofit hospital objectives are largely unknown, for-profits have revealed their objective in their ownership classification. That is, $\alpha=1$. To learn something about $\alpha$ for nonprofit firms with different executive team compositions, I compare their program response to that of for-profits. I estimate the following regression equation:

    \begin{equation}
    \label{eq:forprofit}
    y_{ht} = \beta (for\_profit_h \times post\_programs_t) + \alpha_{h} + \delta_t + \epsilon_{ht}
    \end{equation}

    \noindent where $y_{ht}$ is one of the outcome variables discussed in Section \ref{sec:data}, $\beta$ is the coefficient of interest capturing the effect of being for-profit after the penalties took place, and $\alpha_h$ and $\delta_t$ are hospital and time fixed effects, respectively. For each outcome, I estimate three models where the comparison group differs by hospital type: all nonprofits, nonprofits with a clinically trained executive, and nonprofits without a clinically trained executive. I also directly estimate the difference in response between hospital with and without a clinically trained executive:

    \begin{equation}
    \label{eq:clinical}
    y_{ht} = \beta (no\_MD\_exec_h \times post\_programs_t) + \alpha_{h} + \delta_t + \epsilon_{ht}
    \end{equation}

    An important distinction here is whether the sub-categorization of nonprofit hospitals by executive team is time-invariant. For nonprofits and for-profits, switching overall ownership type is rare, and I limit to those who never switch. However, hospital executive teams are dynamic, and whether or not a hospital employs a clinically trained executive in each period may change. Therefore, I first present effects of having a clinically trained executive among stable executive teams. That is, among hospitals that don't change their propensity to hire a clinically trained executive over time. 
    
    However, under the assumption that these changes are not correlated with the program enactments (see Section \ref{sec:endog}), using the changes can actually be advantageous in better understanding underlying hospital motives. There are two reasons we might see having a clinically trained executive affecting outcomes: first, a clinically trained executive is a signal of the underlying weight placed on profit, $\alpha$. Second, hiring a clinically trained executive who carries out day-to-day operations in a specific way actually changes the underlying $\alpha$. Thus, I use two types of variation in clinically trained executives to disentangle the two: a variable for whether the hospital ever hires a clinically trained executive, and a variable for whether the hospital has a clinically trained executive in 2012 when the programs took place. I use the same empirical specification with these two variables as the independent variation in executive teams. 
    
    As discussed in Section \ref{sec:hrrp}, hospitals had incentive to decrease readmissions immediately when the rules were released in October of 2011, before the penalties were actually determined in October of 2012. However, I still define $post\_penalty$ as occurring in 2012 or later, the first full of hospital response.

    To identify the causal effect of hospital type on hospital program response, I rely on several assumptions. First, I assume that executive teams are not determined endogenously when the programs were enacted. I investigate the validity of this assumption in Section \ref{sec:endog}. Second, I assume that no other unobserved changes occurred in 2012 that differentially impact the outcomes of different hospital types. Finally, I assume that, absent the program enactments, different hospital types would have had parallel trends in outcomes. 

    \section{Results}

    \subsection{Changes in Executive Team}\label{sec:endog}

    Before presenting the main findings, I investigate whether executive team changes occur endogenously due to the programs. If hospitals change their propensity to hire a clinically trained executive because they expect to be penalized or want to gain extra payments, then there is selection in the independent variable. First, I analyze whether changes in clinically trained executives are concentrated around the enactment of both HRRP and HVBP, 2011-2012. Second, I analyze whether hospitals who end up getting penalized through HRRP are more likely to change clinically trained executives on their team than non-penalized hospitals, and similarly for hospitals who end up getting extra payments for high quality of care through HVBP. That is, are hospitals that expect to be affected by the programs more likely to hire or fire clinically trained executives? I consider changes along having any clinically trained executive as well as changes in the number of clinically trained executives. I estimate the following regression equations:

    \begin{equation}
    change_{ht} = \sum_{j=2011}^{2014}\beta_j\mathbf{1}\{t=j\} + \alpha_h + \epsilon_{ht},
    \end{equation}

    \begin{equation}
    change_{ht} = \beta(program\_exposed_{h} \times post\_2011)+ \alpha_h + \delta_t + \epsilon_{ht}.
    \end{equation}

    The variable $program\_exposed_{h}$ is an indicator for whether the hospital eventually was penalized under HRRP or received payments under HVBP. The estimates from this analysis are presented in Table \ref{tab:change_analysis}. Changes in any clinically trained executive are less likely to occur in 2012-2014 relative to 2010, indicating that executives are actually becoming more stable over time along the dimension of hiring clinically trained executives. Further, hospitals who end up being penalized through HRRP or receiving payments through HVBP are not more likely to change their propensity to hire any clinically trained executive. Results are similar when considering changes in the number of clinically trained executives. Thus, I conclude that changes in executive teams are likely not endogenously occurring with the incentive changes due to the programs. 

     \import{Tables}{change_analysis.tex}

     
     \subsection{Readmission and Mortality Rates}

     First, I consider the differential program response of for-profit firms compared to the different sub-samples of nonprofit firms. These results are presented in Table \ref{tab:forprofit_synth}. Models in the left panel estimate the effect of being for-profit after the programs were enacted, compared to nonprofit sub-samples, on readmission rates. There is no statistically meaningful difference between the response of for-profits and nonprofits as a whole, or nonprofits without a clinically trained executive. However, for-profits lower their readmissions by .3ppts compared to nonprofits without clinically trained executives. Models in the right panel estimate the effect of being for-profit after the programs on mortality rates. Here, there is no statistical difference in mortality rate response between different hospital types. 

     \import{Tables}{forprofit_readmort_synth.tex}

     Next, I directly estimate the difference in response by nonprofits with and without clinically trained executives. These results are presented in Table \ref{tab:MD_noMD_synth}, where the left has models with outcome readmission rates and the right has models with outcome mortality rates. Nonprofits without clinically trained executives have a larger decrease in readmissions than those with clinically trained executive by .3ppts, while there is no difference in change in mortality rates. Tables \ref{tab:forprofit_synth} and \ref{tab:MD_noMD_synth} taken together show that, in terms of readmission rates, nonprofits without clinically trained executives behave more similarly to for-profits than they do other nonprofits. Under the assumption that having a clinically trained executive on the leadership team indicates a higher preference for social utility, these findings are consistent with the theoretical prediction presented in Section \ref{sec:model}. 

     \import{Tables}{MD_noMD_readmort_synth.tex}

    \subsubsection{Decomposition}

    However, it is not clear whether these results are due to clinically trained executives being a signal of underlying hospital objectives, or that the leaders themselves make a difference. Therefore, I present a decomposition of the results using two models in Table \ref{tab:MD_noMD_readmort_decomp_synth}, where the variation in executives is either whether the hospital ever has a clinically trained executive, or whether the hospital has a clinically trained executive in 2012 when the programs were enacted. The left panel on readmission rates shows that the difference is response is fully driven by having a clinically trained executive in 2012 compared to having a clinically trained trained executive at another point in time. Again, there is nothing going on with mortality.  

    \import{Tables}{MD_noMD_readmort_decomp_synth.tex}

     


    \subsection{Uncompensated Care and Case Mix Index}

    As a secondary analysis, I present estimates of differential response of potential mechanisms. The first is changing input into another societal benefit measure: uncompensated care, and the second is complexity of patients: case mix index. First, I investigate whether for-profits change these differentially than types of nonprofits in Table \ref{tab:forprofit_uncompCMI_synth}. 

    \import{Tables}{forprofit_uncompCMI_synth.tex}

    Next, I estimate the difference in response for nonprofits with and without clinically trained executives, shown in Table \ref{tab:MD_noMD_uncompCMI_synth}. 

    \import{Tables}{MD_noMD_uncompCMI_synth.tex}

    \subsubsection{Decomposition}

    \import{Tables}{MD_noMD_uncompCMI_decomp_synth.tex}
    

    \section{Conclusion}

    In this paper, I study differential objective between different firm types. While the differences in for-profit and nonprofit hospitals have been studied in the past, it is unclear whether certain nonprofit characteristics make them act more like for-profits. In order to better understand the role of leadership in objectives, I estimate the differential response to a change in incentives among for-profits, nonprofits, and nonprofits with and without a clinically trained executive executives. I find that nonprofits without clinically trained executives respond to incentives much more similarly to for-profits than to nonprofits without clinically trained executives.

	
	\newpage

    \printbibliography

\appendix

 \section{Data}\label{appendixdata}

\subsection{Gathering Hospital Leadership Names}

There is no perfect way to access tax form 990s in bulk over the time period I am considering in this paper. However, using the NonProfit Explorer API seems to be the most straightforward. At the time of writing this, information on using version 2 of the API can be found at \hyperlink{https://projects.propublica.org/nonprofits/api}{https://projects.propublica.org/nonprofits/api}. 
    
There are over 1.5 million nonprofit entities in the US (cite), making it crucially important to be able to filter by type of entity before analyzing any PDFs. The API allows this by filtering a query based on National Taxonomy of Exempt Entities (NTEE) code. I query only nonprofits categorized as E20 (hospitals), E21 (community health systems), and E22 (general hospitals). The API has a pagination limit of 100, meaning I can only pull information on 100 hospitals at a time. Therefore, I filter the query further to only consider one state at a time. The only state that has more than 100 entities registered is California, and thus I subset the California query even further by names that include the word "hospital" and names that don't. I combine all of these subsets and have information on each nonprofits Employee Identification Number. There are 5,588 EINs total in this list. This acts as a list of entities for which I can pull more information. 

I loop through the list of EINs found in the previous step and query more detailed information from the API on that specific EIN. I save the name, secondary name, state, and zip code, all of which do not vary by year. I also save each year's URL that links to the Tax Form 990 PDF. For the sake of a comprehensive data set, I keep years 2006-2020 (I later limit to 2009-2016 when focusing on the Hospital Readmissions Reduction Program). Thus, I finish this step with a panel data set of EIN characteristics and PDF locations. Importantly, there are multiple types of Tax Form 990s depending on the size of the nonprofit. In many cases, one nonprofit has at least two different forms filed in a given year. I filter out any EIN-years for which there are no PDFs on file. The data on PDF locations contains 4,012 EINs and 61,363 EIN-year-tax forms.

It is crucial to the analysis to be able to link these nonprofits with other sources of data to recover penalties from HRRP, bed size, and outcomes of interest (definitely need to talk more about outcomes). Therefore, I take a conservative approach to matching EINs to American Hospital Association (AHA) ID, which links fairly easily to Medicare ID numbers, based on name and location. First, I will discuss limitations and cleaning that I do to the AHA data and tax form data separately before doing any matching. 

I download the AHA data from Wharton Research Data Services. I filter only to hospitals in the contiguous US, Alaska, and Hawaii (excluding places like Puerto Rico), classified as nonprofit or state/community, and those that are general acute care. I also filter out any hospitals who weren't present in the data (or change system ID) in 2009-2015, meaning they either closed or were acquired. Due to the survey nature of this data, a hospital name may look slightly different from one year to the next. For example, "Waldo County General Hospital" is also Waldo County General Hospital Maine Health". Further, zip codes may change by one or two digits, making them unreliable to match based on. To deal with this, I first keep only unique AHA ID, name, zip, state, and system name combinations. Then, I convert the data from long to wide so that each AHA ID occurs only once, but may have multiple names, zip codes, or system names associated with it.

I consider which nonprofit entities are not likely to be hospitals and drop them. There are numerous foundations or auxiliary nonprofits with the purpose of raising funds for the hospital, but do not actually care for patient. I filter out any nonprofit with "foundation" or "auxiliary" in the name. I also filter out various specialty centers that fell into the general hospital category, such as hospice or cancer centers. 

I then proceed matching based on names in multiple layers. I focus on exact string matches, so I remove all spaces and common characters that could cause mismatches such as \&, ', -, and inc. Next, I take each AHA name and look for exact matches in a nonprofit's first or secondary name only for nonprofits in the same state as the AHA hospital. When an exact match is found, I record the link between AHA ID and EIN. In this first layer of matching, 860 hospitals in the AHA data are linked to an EIN, equivalent to 31\% of AHA nonprofit hospitals in the sample. 

In the next layer of matching, I remove common words such as "healthcare", "regional", "hospital", etc. That way if there are subtle differences in names, removing common words may allow for an exact match. Again, I take each AHA hospital name and look for exact matches in the nonprofits within the same state. This adds an additional 90 hospital matches, accounting for a total of 34.5\% of AHA hospitals. 

In some cases, tax forms are associated with a system of hospitals instead of one individual hospital. Thus, I create another variable that captures the names of systems which match. The process of matching is the same, the only difference is that now I am considering system names from the AHA data instead of hospital names. A total of 1,136 AHA hospitals have an EIN match on hospital name, system name, or both. This is roughly 41\% of the sample. These hospitals become the main sample for my analysis. While not capturing a large majority of AHA hospitals that are categorized as nonprofit, I would rather be conservative in selecting hospitals which I am confident that the characteristics and measurement of the independent and dependent variables are accurate. 

(add a paragraph about validity of matches)

 Now that I have a sample of hospitals, the next step is to extract the names of the people in charge of these hospitals from the Tax Form 990 PDFs. In the data set of hospital PDF URLs that I collected earlier, I limit to the hospitals with solid matches described above. I then loop through each EIN, downloading each PDF locally and using tesseract package in R to extract text from the relevant pages of the PDF using OCR text extraction methods. In particular, I loop through each page of the PDF, look for the title associated with leadership names: ``Officers, Directors, Trustees, Key Employees, and Highest Compensated Employees", and save all the text from any pages where this title is found. I save the text to a list of all EIN, years present. 

One tricky aspect of the NonProfit Explorer API is that, only in some cases, if two forms are present for an EIN, year, only the first one (which is typically not the one with the relevant information) is pulled. Therefore, for some hospitals, a couple years will have gaps in text extraction data. I locate EIN, years where this problem is occurring, and a team of RAs locates and downloads the correct forms manually. I extract text from these manually downloaded forms in the same manner as above. 

The form of the text data is a data frame with one column, where each line of text is saved in a different row. I write a text cleaning package that locates names, positions, titles, and indications of resigning. I will now describe this function in three parts: preliminary cleaning of strings, locating names, and locating positions, titles, and key words surrounding resigning. 

Typically on the same page as the names and positions is a list of the highest compensated employees and their compensation. In order to not record extra names, I filter out any rows after the start of this section. I then remove any digits, parentheses and brackets, other punctuation, letters that occur by themselves, two letter ``words" that have no meaning, and excess space between words. I then split up the phrase into individual words, so one phrase with 5 words is broken up into 5 variables. 

Next, I locate first and last names in the data. 

\includegraphics[width=\textwidth]{Objects/has_doc_avg_map.pdf}


\section{Full Sample Regression Results}

\import{Tables}{MD_noMD_readmort_fullsample.tex}

\import{Tables}{forprofit_readmort_fullsample.tex}

\import{Tables}{MD_noMD_uncompCMI_fullsample.tex}

\import{Tables}{forprofit_uncompCMI_fullsample.tex}

\section{Matched Sample Regression Results}

\import{Tables}{MD_noMD_readmort_matchsample.tex}

\import{Tables}{forprofit_readmort_matchsample.tex}

\import{Tables}{MD_noMD_uncompCMI_matchsample.tex}

\import{Tables}{forprofit_uncompCMI_matchsample.tex}



    

    

    

    

    

    

	
	
	


\end{document}

